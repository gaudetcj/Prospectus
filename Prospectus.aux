\relax 
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Quaternions}{6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Quaternion Algebra}{6}}
\newlabel{eq:quaternion1}{{1.1}{6}}
\newlabel{eq:quarternion2}{{1.2}{7}}
\newlabel{eq:quarternion3}{{1.3}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}Addition and Multiplication}{7}}
\newlabel{eq:q}{{1.4}{7}}
\newlabel{eq:p}{{1.5}{7}}
\newlabel{eq:quataddition}{{1.6}{7}}
\newlabel{eq:quatmult}{{1.7}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}Conjugate, Norm, and Inverse}{8}}
\newlabel{eq:quatconjugate}{{1.8}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Geometric Representation of Quaternions}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Complex Algebra}{8}}
\newlabel{eq:complexalgebra}{{1.9}{8}}
\newlabel{eq:complexaddition}{{1.10}{9}}
\newlabel{eq:complexmult}{{1.11}{9}}
\newlabel{eq:complexlength}{{1.12}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Complex Rotation Operation}{9}}
\newlabel{eq:euler}{{1.13}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.3}Quaternion Rotation Operation}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces $\mathbb  {R}^3$ can be viewed as a subspace of quaternions called pure quaternions which have a real part of zero.\relax }}{10}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{f:r3}{{1.1}{10}}
\newlabel{eq:Lq}{{1.14}{10}}
\newlabel{eq:unitquat}{{1.15}{11}}
\newlabel{eq:p11}{{1.16}{11}}
\citation{hubel1968receptive}
\citation{lecun1990handwritten}
\citation{hecht1988theory}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Introduction To Convolutional Neural Networks}{13}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Basic CNN Components}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces The architecture for LeNet-5, which is composed of repeating convolution and pooling layers.\relax }}{14}}
\newlabel{f:lenet}{{2.1}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Convolutional Layer}{14}}
\newlabel{eq:convbasic}{{2.1}{14}}
\citation{convolution}
\citation{convolution}
\newlabel{eq:activationbasic}{{2.2}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Convolution operation performed on a single feature location and one convolution kernel \cite  {convolution}.\relax }}{15}}
\newlabel{f:convolution}{{2.2}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Pooling Layer}{15}}
\citation{maxpooling}
\citation{maxpooling}
\citation{rumelhart1985learning}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Example max pooling operation with a size of 2x2. A 2x2 window is moved over the input with a stride of 2 and the maximum value of the window is taken \cite  {maxpooling}.\relax }}{16}}
\newlabel{f:maxpool}{{2.3}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}CNN Common Tasks}{16}}
\citation{maldonado2007road}
\citation{li2015automatic}
\citation{lyksborg2015ensemble}
\citation{kainz2015semantic}
\citation{havaei2017brain}
\citation{chen2013vehicle}
\citation{du2016fused}
\citation{nair2010rectified}
\citation{glorot2011deep}
\citation{krizhevsky2012imagenet}
\citation{zeiler2013rectified}
\citation{maas2013rectifier}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}State of the Art}{18}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{StateOfTheArt}{{3}{18}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Recent Advances in Training Neural Networks}{18}}
\newlabel{s:NNAdvances}{{3.1}{18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Activation Functions}{18}}
\@writefile{toc}{\contentsline {paragraph}{ReLU:}{18}}
\newlabel{e:relu}{{3.1}{18}}
\citation{maas2013rectifier}
\citation{he2015delving}
\citation{clevert2015fast}
\@writefile{toc}{\contentsline {paragraph}{LReLU:}{19}}
\newlabel{e:lrelu}{{3.2}{19}}
\@writefile{toc}{\contentsline {paragraph}{PReLU:}{19}}
\newlabel{e:prelu}{{3.3}{19}}
\@writefile{toc}{\contentsline {paragraph}{ELU:}{19}}
\citation{trottier2016parametric}
\citation{trottier2016parametric}
\citation{hinton2012improving}
\citation{wang2013fast}
\citation{ba2013adaptive}
\citation{tompson2015efficient}
\newlabel{e:elu}{{3.4}{20}}
\@writefile{toc}{\contentsline {paragraph}{PELU:}{20}}
\newlabel{e:pelu}{{3.5}{20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Regularization}{20}}
\@writefile{toc}{\contentsline {paragraph}{Dropout:}{20}}
\newlabel{eq:dropout}{{3.6}{20}}
\citation{ioffe2015batch}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Examples of some of the discussed activation functions. From top to bottom and left to right: ReLU, LReLU, PReLU, and ELU. \cite  {}\relax }}{21}}
\newlabel{f:activations}{{3.1}{21}}
\citation{lin2013network}
\@writefile{toc}{\contentsline {paragraph}{Batch Normalization:}{22}}
\newlabel{eq:BN1}{{3.7}{22}}
\newlabel{eq:BN2}{{3.8}{22}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Architecture Improvements}{22}}
\citation{szegedy2015going}
\citation{szegedy2015going}
\citation{szegedy2015going}
\citation{he2015deep}
\citation{he2015deep}
\citation{he2015deep}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces An inception block from \cite  {szegedy2015going}. Notice the 1x1 convolutions before the 3x3 and 5x5 convolutions are reducing the number of feature channels. This reduces the number of multiplications that must be performed.\relax }}{23}}
\newlabel{f:inceptionblock}{{3.2}{23}}
\citation{long2015fully}
\citation{long2015fully}
\citation{long2015fully}
\citation{long2015fully}
\citation{long2015fully}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces A residual block from \cite  {he2015deep}.\relax }}{24}}
\newlabel{f:resblock}{{3.3}{24}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Recent Advances in CNNs for Semantic Segmentation}{24}}
\newlabel{s:RecentAdvsCNNs}{{3.2}{24}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Fully Convolutional Networks for Semantic Segmentation}{25}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Backwards convolution with a stride of 2 upsampling a 3x3 image to a 5x5 image. Notice the 3x3 image is padded with zeros, the white tiles. The shaded grey area is the actual convolution kernel, which is learned during training.\relax }}{25}}
\newlabel{f:deconv}{{3.4}{25}}
\citation{ronneberger2015u}
\citation{long2015fully}
\citation{ronneberger2015u}
\citation{ronneberger2015u}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Transforming fully connected layers into convolution layers enables a classification net to output a heatmap \cite  {long2015fully}. This is achieved by using 1x1 convolutions instead of fully connected layers and will produce a tiny heatmap of classes. This change also make the network become independent of input image size.\relax }}{26}}
\newlabel{f:fcn1}{{3.5}{26}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}U-Net: Convolutional Networks for Biomedical Image Segmentation}{26}}
\newlabel{s:unet}{{3.2.2}{26}}
\citation{maggiori2016learning}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Three different architectures from \cite  {long2015fully}. The first uses no short connections, the second forwards information from pool4, and the third forwards information from both pool3 and pool4.\relax }}{27}}
\newlabel{f:fcn2}{{3.6}{27}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces U-Net architecture (example for 32x32 pixels in the lowest resolution). Each blue box corresponds to a multi-channel feature map. The number of channels is denoted on top of the box. The x-y-size is provided at the lower left edge of the box. White boxes represent copied feature maps. The arrows denote the different operations. \cite  {ronneberger2015u}.\relax }}{28}}
\newlabel{f:unet}{{3.7}{28}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Learning Iterative Processes with Recurrent Neural Networks to Correct Satellite Image Classification Maps}{28}}
\newlabel{PDERNN}{{3.2.3}{28}}
\citation{maggiori2016learning}
\citation{maggiori2016learning}
\citation{maggiori2016learning}
\citation{maggiori2016learning}
\citation{goodfellow2014generative}
\newlabel{eq:cnnrnnset}{{3.9}{29}}
\newlabel{eq:cnnrnn1}{{3.10}{29}}
\newlabel{eq:}{{3.11}{29}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.4}Semantic Segmentation using Adversarial Networks}{29}}
\@writefile{toc}{\contentsline {subsubsection}{Brief overview of GANs}{29}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces One iteration of the RNN represented as common neural network layers. The block approximates $\delta u_{k,t}$ and then adds it to $u_{k,t}$ to estimate $\delta u_{k,t}$. \cite  {maggiori2016learning}\relax }}{30}}
\newlabel{f:cnnrnn1}{{3.8}{30}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces The whole RNN shown by multiple blocks from Fig.3.8\hbox {} with shared weights. \cite  {maggiori2016learning}.\relax }}{30}}
\newlabel{f:cnnrnn2}{{3.9}{30}}
\citation{ratliff2013characterization}
\citation{radford2015unsupervised}
\citation{salimans2016improved}
\citation{arjovsky2017wasserstein}
\citation{mao2017lsgan}
\citation{luc2016semantic}
\@writefile{toc}{\contentsline {subsubsection}{GANs for segmentation}{32}}
\citation{luc2016semantic}
\citation{luc2016semantic}
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces GAN formulation of semantic segmentation from \cite  {luc2016semantic}. Left: segmentation net takes RGB image as input, and produces per-pixel class predictions. Right: Adversarial net takes label map as input and produces class label (1=ground truth, or 0=synthetic).\relax }}{33}}
\newlabel{f:seggan}{{3.10}{33}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Open Questions}{33}}
\citation{emdata}
\citation{quan2016fusionnet}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Work Completed}{34}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Models}{34}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Training}{35}}
\citation{chollet2015}
\citation{ronneberger2015u}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Experimental Setup}{36}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Results}{36}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Basic Comparison}{36}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}Applying Batch Normalization}{37}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces The model architecture. Feature maps from the down path get summed with feature maps of the corresponding size in the up path. The ResBlock types are shown in Figs.\nobreakspace  {}4.2a\hbox {}\nobreakspace  {}\&\nobreakspace  {}4.2b\hbox {} and the DConvolution and UConvolution are shown in Fig.\nobreakspace  {}4.2c\hbox {} and Fig.\nobreakspace  {}4.2d\hbox {} respectively.\relax }}{38}}
\newlabel{f:model}{{4.1}{38}}
\newlabel{f:basic}{{4.2a}{39}}
\newlabel{sub@f:basic}{{a}{39}}
\newlabel{f:multi}{{4.2b}{39}}
\newlabel{sub@f:multi}{{b}{39}}
\newlabel{f:dconv}{{4.2c}{39}}
\newlabel{sub@f:dconv}{{c}{39}}
\newlabel{f:uconv}{{4.2d}{39}}
\newlabel{sub@f:uconv}{{d}{39}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Model components.\relax }}{39}}
\newlabel{f:modelpieces}{{4.2}{39}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces The loss and validation loss during training for the baseline models.\relax }}{40}}
\newlabel{f:baseline-loss}{{4.3}{40}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Sample segmentation on a test image for the baseline models. The test image is shown in its normalize stated, which is scaling the values between minus one and one. From left to right: test image, U-Net segmentation, our model, and our model with multi-scale convolution. The segmentations are shown in a red to blue color map where red is 0 and blue is 1.\relax }}{41}}
\newlabel{f:baseline}{{4.4}{41}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces The loss and validation loss during training for the batchnorm models.\relax }}{42}}
\newlabel{f:batchnorm-loss}{{4.5}{42}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Sample segmentation on a test image for the batchnorm models. From left to right: test image, U-Net segmentation, our model, and our model with multi-scale convolution.\relax }}{42}}
\newlabel{f:batchnorm}{{4.6}{42}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Additional Research}{43}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Timeline}{44}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Refinement RNN}{44}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}GAN Model}{44}}
\bibstyle{alpha}
\bibdata{bib}
\@writefile{toc}{\vspace *{\baselineskip }}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{45}}
\bibcite{arjovsky2017wasserstein}{ACB17}
\bibcite{convolution}{App00}
\bibcite{ba2013adaptive}{BF13}
\bibcite{chollet2015}{Cho15}
\bibcite{clevert2015fast}{CUH15}
\bibcite{chen2013vehicle}{CXLP13}
\bibcite{du2016fused}{DEKLD16}
\bibcite{glorot2011deep}{GBB11}
\bibcite{goodfellow2014generative}{GPAM{$^{+}$}14}
\bibcite{havaei2017brain}{HDWF{$^{+}$}17}
\bibcite{hecht1988theory}{HN{$^{+}$}88}
\bibcite{hinton2012improving}{HSK{$^{+}$}12}
\bibcite{hubel1968receptive}{HW68}
\bibcite{he2015deep}{HZRS15a}
\bibcite{he2015delving}{HZRS15b}
\bibcite{ioffe2015batch}{IS15}
\bibcite{maxpooling}{Kar13}
\bibcite{kainz2015semantic}{KPU15}
\bibcite{krizhevsky2012imagenet}{KSH12}
\bibcite{lecun1990handwritten}{LBD{$^{+}$}90}
\bibcite{luc2016semantic}{LCCV16}
\bibcite{lin2013network}{LCY13}
\bibcite{li2015automatic}{LJH15}
\bibcite{lyksborg2015ensemble}{LPAL15}
\bibcite{long2015fully}{LSD15}
\bibcite{maldonado2007road}{MBLAGJ{$^{+}$}07}
\bibcite{maas2013rectifier}{MHN13}
\bibcite{maggiori2016learning}{MTCA16}
\bibcite{nair2010rectified}{NH10}
\bibcite{emdata}{onsiEs12}
\bibcite{quan2016fusionnet}{QHJ16}
\bibcite{ratliff2013characterization}{RBS13}
\bibcite{ronneberger2015u}{RFB15}
\bibcite{rumelhart1985learning}{RHW85}
\bibcite{radford2015unsupervised}{RMC15}
\bibcite{salimans2016improved}{SGZ{$^{+}$}16}
\bibcite{szegedy2015going}{SLJ{$^{+}$}15}
\bibcite{trottier2016parametric}{TGCd16}
\bibcite{tompson2015efficient}{TGJ{$^{+}$}15}
\bibcite{wang2013fast}{WM13}
\bibcite{mao2017lsgan}{XM17}
\bibcite{zeiler2013rectified}{ZRM{$^{+}$}13}
\citation{convolution}
\citation{maxpooling}
\citation{szegedy2015going}
\citation{he2015deep}
\@writefile{toc}{\contentsline {chapter}{List of Figures}{52}}
\citation{long2015fully}
\citation{long2015fully}
\citation{ronneberger2015u}
\citation{maggiori2016learning}
\citation{maggiori2016learning}
\citation{luc2016semantic}
\@writefile{toc}{\contentsline {chapter}{List of Tables}{55}}
